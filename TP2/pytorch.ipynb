{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction a PyTorch\n",
    "\n",
    "Based on https://github.com/mila-udem/welcome_tutorials/tree/master/pytorch By Sandeep Subramanian, https://github.com/jcjohnson/pytorch-examples by Justin Johnson and official documentation http://pytorch.org/tutorials/beginner/deep_learning_60min_blitz.html ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensor\n",
    "\n",
    "Tensors are similar to numpy array, but they can also be used on GPUs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3, 4])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch.autograd import Variable\n",
    "# convert numpy array to tensor\n",
    "torch.from_numpy(np.array([1,2,3,4]))  # LongTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 2., 3., 4.], dtype=torch.float64)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.from_numpy(np.array([1.,2,3,4]))  # Double Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 2., 3., 4.])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.FloatTensor([1,2,3,4])\n",
    "torch.Tensor([1,2,3,4])  # float tensor by default, can change it with torch.set_default_tensor_type('torch.FloatTensor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.Tensor([1,2,3,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0000, 1.4142, 1.7321, 2.0000])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.sqrt()  # similar functionality as numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 1])\n"
     ]
    }
   ],
   "source": [
    "x = x.view(-1, 1)  # the torch reshape function\n",
    "print(x.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1.],\n",
       "        [2., 2.],\n",
       "        [3., 3.],\n",
       "        [4., 4.]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat([x, x], 1)  # concatenate 2 vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autograd\n",
    "\n",
    "Autograd provides automatic differentiation on all operations perform on tensors. To be able to use Autograd, you must wrap your tensors in a Variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.]], requires_grad=True)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = Variable(x, requires_grad=False)\n",
    "w = Variable(torch.ones(4, 1), requires_grad=True)\n",
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(w.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "dot: Expected 1-D argument self, but got 2-D",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-2cfa5d8249c1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: dot: Expected 1-D argument self, but got 2-D"
     ]
    }
   ],
   "source": [
    "z = torch.dot(w, x)\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optim and loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD([w], lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'z' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-d1156426382c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mz\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'z' is not defined"
     ]
    }
   ],
   "source": [
    "optimizer.zero_grad()\n",
    "z.backward()\n",
    "print(w.grad)\n",
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      " 0.9900\n",
      " 0.9800\n",
      " 0.9700\n",
      " 0.9600\n",
      "[torch.FloatTensor of size 4x1]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      " 0.7960\n",
      " 0.5920\n",
      " 0.3880\n",
      " 0.1840\n",
      "[torch.FloatTensor of size 4x1]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "loss_fn = torch.nn.MSELoss()\n",
    "z = torch.dot(w, x)\n",
    "target = Variable(torch.zeros(1))\n",
    "optimizer.zero_grad()\n",
    "loss = loss_fn(z, target)\n",
    "loss.backward()  # retain_graph=True, if you need to call loss.backward() again without optimizer.step()\n",
    "optimizer.step()\n",
    "print(w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fashion MNIST\n",
    "\n",
    "based on MNIST tutorial: https://github.com/pytorch/examples/blob/master/mnist/main.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline  \n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "from fashion import FashionMNIST\n",
    "import torchvision.transforms as transforms\n",
    "from torch import nn\n",
    "from torch import optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = FashionMNIST('../data', train=True, download=True,\n",
    "                   transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ]))\n",
    "\n",
    "valid_data = FashionMNIST('../data', train=True, download=True,\n",
    "                   transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_idx = np.random.choice(train_data.train_data.shape[0], 54000, replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.train_data = train_data.train_data[train_idx, :]\n",
    "train_data.train_labels = train_data.train_labels[torch.from_numpy(train_idx).type(torch.LongTensor)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = np.ones(60000)\n",
    "mask[train_idx] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_data.train_data = valid_data.train_data[torch.from_numpy(np.argwhere(mask)), :].squeeze()\n",
    "valid_data.train_labels = valid_data.train_labels[torch.from_numpy(mask).type(torch.ByteTensor)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "test_batch_size = 100\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data,\n",
    "    batch_size=batch_size, shuffle=True)\n",
    "\n",
    "valid_loader = torch.utils.data.DataLoader(valid_data,\n",
    "    batch_size=batch_size, shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    FashionMNIST('../data', train=False, transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ])),\n",
    "    batch_size=test_batch_size, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x11cc9ce48>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(train_loader.dataset.train_data[1].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x11ce6b048>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(train_loader.dataset.train_data[10].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FcNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(28*28, 512)\n",
    "        self.fc2 = nn.Linear(512, 10)\n",
    "    \n",
    "    def forward(self, image):\n",
    "        batch_size = image.size()[0]\n",
    "        x = image.view(batch_size, -1)\n",
    "        x = F.sigmoid(self.fc1(x))\n",
    "        x = F.log_softmax(self.fc2(x), dim=1)\n",
    "        return x    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, optimizer):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        # data, target = Variable(data, volatile=True).cuda(), Variable(target).cuda() # if you have access to a gpu\n",
    "        data, target = Variable(data), Variable(target)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)  # calls the forward function\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    return model\n",
    "\n",
    "\n",
    "def valid(model, valid_loader):\n",
    "    model.eval()\n",
    "    valid_loss = 0\n",
    "    correct = 0\n",
    "    for data, target in valid_loader:\n",
    "        # data, target = Variable(data, volatile=True).cuda(), Variable(target).cuda() # if you have access to a gpu\n",
    "        data, target = Variable(data, volatile=True), Variable(target)\n",
    "        output = model(data)\n",
    "        valid_loss += F.nll_loss(output, target, size_average=False).data[0] # sum up batch loss\n",
    "        pred = output.data.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "        correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
    "\n",
    "    valid_loss /= len(valid_loader.dataset)\n",
    "    print('\\n' + \"valid\" + ' set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        valid_loss, correct, len(valid_loader.dataset),\n",
    "        100. * correct / len(valid_loader.dataset)))\n",
    "    return correct / len(valid_loader.dataset)\n",
    "\n",
    "    \n",
    "def test(model, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    for data, target in test_loader:\n",
    "        # data, target = Variable(data, volatile=True).cuda(), Variable(target).cuda() # if you have access to a gpu\n",
    "        data, target = Variable(data, volatile=True), Variable(target)\n",
    "        output = model(data)\n",
    "        test_loss += F.nll_loss(output, target, size_average=False).data[0] # sum up batch loss\n",
    "        pred = output.data.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "        correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print('\\n' + \"test\" + ' set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))\n",
    "    \n",
    "    \n",
    "def experiment(model, epochs=10, lr=0.001):\n",
    "    best_precision = 0\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        model = train(model, train_loader, optimizer)\n",
    "        precision = valid(model, valid_loader)\n",
    "    \n",
    "        if precision > best_precision:\n",
    "            best_precision = precision\n",
    "            best_model = model\n",
    "    return best_model, best_precision\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:20: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "invalid index of a 0-dim tensor. Use tensor.item() to convert a 0-dim tensor to a Python number",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-b7393907ee15>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mFcNetwork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# add your models in the list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;31m# model.cuda()  # if you have access to a gpu\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprecision\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexperiment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mprecision\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mbest_precision\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mbest_precision\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprecision\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-26-c8984a9c5bc4>\u001b[0m in \u001b[0;36mexperiment\u001b[0;34m(model, epochs, lr)\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m         \u001b[0mprecision\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mprecision\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mbest_precision\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-26-c8984a9c5bc4>\u001b[0m in \u001b[0;36mvalid\u001b[0;34m(model, valid_loader)\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvolatile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mvalid_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize_average\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# sum up batch loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# get the index of the max log-probability\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mcorrect\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview_as\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: invalid index of a 0-dim tensor. Use tensor.item() to convert a 0-dim tensor to a Python number"
     ]
    }
   ],
   "source": [
    "best_precision = 0\n",
    "for model in [FcNetwork()]:  # add your models in the list\n",
    "    # model.cuda()  # if you have access to a gpu\n",
    "    model, precision = experiment(model)\n",
    "    if precision > best_precision:\n",
    "        best_precision = precision\n",
    "        best_model = model\n",
    "\n",
    "test(best_model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
